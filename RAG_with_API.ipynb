{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sibikrish3000/chatbot_workshop/blob/main/RAG_with_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **What is RAG?**\n",
        "- **Definition**: A hybrid approach combining retrieval-based and generative models.\n",
        "- **Purpose**: Enhances chatbots by retrieving relevant documents from a knowledge base and generating context-aware responses.\n",
        "\n",
        "### **Key Components**:\n",
        "1. **Retrieval**:\n",
        "   - Searches a database/documents (e.g., Wikipedia, company files) for chunks relevant to the user’s query.\n",
        "   - Uses semantic search (e.g., cosine similarity with embeddings) to find contextually similar text..\n",
        "2. **Augmentation**:\n",
        "  - Injects the retrieved information into the prompt as context for the generative model.\n",
        "3. **Generation**:\n",
        "   - Employs a language model (e.g., DeepSeek, Qwen) to generate natural language responses based on retrieved context.\n",
        "\n",
        "### **Workflow**:\n",
        "1. **Query Input**: User submits a question.\n",
        "2. **Document Retrieval**: Relevant documents are fetched from the knowledge base.\n",
        "3. **Prompt Construction**: Context and query are combined into a prompt.\n",
        "4. **Response Generation**: The model generates a response using the context.\n",
        "5. **Output**: Cleaned and formatted response is returned to the user.\n",
        "\n",
        "### **Benefits**:\n",
        "- Accurate and context-aware responses.\n",
        "- Scalable with large knowledge bases.\n",
        "- Improves conversational flow and user satisfaction."
      ],
      "metadata": {
        "id": "wB5b4hm-KEaT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Advavance Rag Implemenation Flow chart:**[![3JB0VdF.md.png](https://iili.io/3JB0VdF.png)](https://freeimage.host/i/3JB0VdF)"
      ],
      "metadata": {
        "id": "2k6WRFykKV-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Naive RAG:**\n",
        "![](https://iili.io/3JRglls.png)\n",
        "### **Workflow in RAG**\n",
        "1. **Embedding Conversion**:  \n",
        "   - The query and all documents are converted into dense vector representations via an embedding model.\n",
        "2. **Similarity Calculation**:  \n",
        "   - Cosine similarity is computed between the query vector and every document vector.\n",
        "3. **Top-k Retrieval**:  \n",
        "   - Documents with the highest cosine scores are selected as context for the generative model (e.g., GPT-3).\n",
        "4. **Generation**:  \n",
        "   - The retrieved documents inform the generative model to produce a relevant, accurate answer.\n",
        "![](https://iili.io/3JYWszg.png)"
      ],
      "metadata": {
        "id": "Qd-fvTJTvDTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Documents\n",
        "question = \"i love coding\" # @param [\"What kinds of pets do I like?\"] {\"allow-input\":true}\n",
        "document = \"My favorite pet is a cat.\"    # @param [\"My favorite pet is a cat.\"] {\"allow-input\":true}"
      ],
      "metadata": {
        "id": "74fYGlZ1K8ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1 : Indexing\n",
        "![](https://iili.io/3JBjI1f.png)"
      ],
      "metadata": {
        "id": "xjpEUdIoLmpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "9NYLGc1-L0f9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What are tokens?\n",
        ">Tokens can be thought of as pieces of words. Before the API processes the request, the input is broken down into tokens. These tokens are not cut up exactly where the words start or end - tokens can include trailing spaces and even sub-words. Here are some helpful rules of thumb for understanding tokens in terms of lengths:\n",
        "\n",
        "1 token ~= 4 chars in English\n",
        "\n",
        "1 token ~= ¾ words\n",
        "\n",
        "100 tokens ~= 75 words\n",
        "\n",
        "Or\n",
        "\n",
        "1-2 sentence ~= 30 tokens\n",
        "\n",
        "1 paragraph ~= 100 tokens\n",
        "\n",
        "1,500 words ~= 2048 tokens"
      ],
      "metadata": {
        "id": "dICcW3tBP4Bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    encoding = tiktoken.get_encoding(encoding_name)\n",
        "    enc_str=encoding.encode(string)\n",
        "    print(f'encoded string: {enc_str}')\n",
        "    dec_str=encoding.decode(enc_str)\n",
        "    print(f'Decode string: {dec_str}')\n",
        "    num_tokens = len(enc_str)\n",
        "    return num_tokens\n",
        "\n",
        "num_tokens_from_string(question, \"cl100k_base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gz5L6YrNLJnf",
        "outputId": "bd1fb4c4-716f-4c11-d93e-14171adbf9ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoded string: [72, 3021, 11058]\n",
            "Decode string: i love coding\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2 : Embedding\n",
        ">embedding is a representation of data (such as words, sentences, or other entities) in a continuous vector space. These vectors are typically dense, meaning they consist of real numbers rather than sparse binary values, and are designed to capture semantic relationships between the items being represented.\n",
        "\n",
        "Key Concepts of Embeddings:\n",
        "\n",
        "Vector Representation :\n",
        "\n",
        "Embeddings map discrete objects (e.g., words, images, or categories) into continuous vector spaces. For example, a word like \"king\" might be represented as a vector [0.25, -0.1, 0.9, ...] in a high-dimensional space.\n",
        "\n",
        "----\n",
        "\n",
        "Semantic Meaning :\n",
        "\n",
        "The key idea behind embeddings is that similar items will have similar vector representations. For instance, in word embeddings, semantically related words (like \"king\" and \"queen\") will have vectors that are close to each other in the vector space.\n",
        "\n",
        "* Suppose you have the words \"king\", \"queen\", \"man\", and \"woman\". After training, their embeddings might look something like this in a simplified 2D space:\n",
        "```\n",
        "king   -> [0.8, 0.2]\n",
        "queen  -> [0.7, 0.3]\n",
        "man    -> [0.9, 0.1]\n",
        "woman  -> [0.8, 0.4]\n",
        "```\n",
        "In this case, the vector for \"king\" is closer to \"man\" than to \"woman\", and \"queen\" is closer to \"woman\". Additionally, the relationship between \"king\" and \"queen\" might be similar to the relationship between \"man\" and \"woman\", which can be captured by vector arithmetic:\n",
        "```\n",
        "king - man + woman ≈ queen\n",
        "```"
      ],
      "metadata": {
        "id": "om-JWDfSMPuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "id": "XhHC3Ub_NfuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "embd = HuggingFaceEmbeddings()\n",
        "query_result = embd.embed_query(question)\n",
        "document_result = embd.embed_query(document)\n",
        "print(f'query_result: {query_result}')\n",
        "print(f'query_result length: {len(query_result)}')\n",
        "print(f'document_result: {document_result}')\n",
        "print(f'document_result length: {len(document_result)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1gN9KhDMUy8",
        "outputId": "f3dd4baa-4e5a-45a3-80f1-73617041e260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-275cde755a8d>:2: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
            "  embd = HuggingFaceEmbeddings()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query_result: [-0.029304862022399902, 0.06239829212427139, -0.064301036298275, 0.014795470051467419, 0.01879589818418026, 0.0608164444565773, -0.07478100061416626, -0.01659526117146015, -0.030508002266287804, 0.030598340556025505, 0.025639722123742104, 0.038709282875061035, 0.0024956215638667345, 0.1047094389796257, 0.009299385361373425, 0.01294324453920126, -0.022103862836956978, -0.022564884275197983, -0.03605072572827339, 0.00011076000373577699, 0.02002040110528469, 0.03963882476091385, -0.042874306440353394, -0.02453198842704296, -0.004480579402297735, -0.009060772135853767, 0.009875593706965446, -0.06069997325539589, -0.03463570773601532, 0.05754446983337402, -0.002160274889320135, -0.0021566080395132303, -0.005808633752167225, 0.0028201164677739143, 1.6196588603634154e-06, 0.004496601410210133, -0.015027355402708054, -0.002435229951515794, -0.05663324519991875, 0.02231852523982525, -0.030137047171592712, -0.021930424496531487, -0.02272447571158409, 0.007798372767865658, -0.0473465621471405, 0.023754384368658066, 0.0917426347732544, -0.05870368704199791, 0.029528871178627014, 0.00017409477732144296, -0.004552232567220926, -0.016986533999443054, -0.017124490812420845, -0.022883981466293335, 0.019126415252685547, 0.033929698169231415, 0.01704089716076851, 0.05406181514263153, 0.09688348323106766, 0.010747317224740982, -0.02364988997578621, -0.047129202634096146, 0.04012304171919823, 0.01001310721039772, 0.07217058539390564, 0.05043113976716995, 0.003910656087100506, -0.02521788515150547, 0.028067052364349365, 0.021775998175144196, 0.009601669386029243, -0.03881899267435074, -0.002839385299012065, 0.02536410093307495, 0.019633812829852104, -0.07761761546134949, -0.03287467733025551, 0.0472879596054554, 0.0025174091570079327, -0.01160526368767023, -0.006696982774883509, 0.008956176228821278, -0.008238988928496838, -0.02282298356294632, 0.009934370405972004, -0.0283819492906332, 0.0003002817975357175, -0.019606273621320724, -0.04657846316695213, 0.06873288750648499, 0.003942378330975771, -0.017649900168180466, 0.03996951878070831, 0.055884163826704025, -0.023013940081000328, 0.004712925758212805, -0.008467601612210274, 0.018591998144984245, 0.0064796824008226395, 0.024042172357439995, 0.002820840571075678, 0.045340172946453094, -0.007313026115298271, 0.02072312869131565, -0.019276544451713562, 0.01033987756818533, 0.01413769368082285, -0.002880614250898361, -0.0003788950853049755, 0.05597872659564018, -0.056972354650497437, -0.03653380274772644, 0.009467170573771, 0.028701959177851677, 0.010220987722277641, 0.08910344541072845, 0.01534245628863573, 0.06612782180309296, 0.007736260537058115, 0.01912735402584076, -0.017602108418941498, 0.004523506388068199, 0.013643178157508373, 0.059951893985271454, 0.04139655455946922, -0.062391169369220734, -0.04053959622979164, 0.004351409617811441, -0.043168794363737106, -0.010091309435665607, -0.03326224163174629, -0.012742179445922375, -0.0008257169974967837, -0.04352286085486412, -0.0007254367228597403, 0.02952035516500473, -0.06073034927248955, 0.02683776244521141, 0.04452318698167801, -0.03760207071900368, -0.007658577058464289, 0.003347768448293209, 0.02004939690232277, -0.03437725082039833, 0.02030937746167183, 0.008979144506156445, -0.007191873155534267, -0.0546085424721241, -0.00751173822209239, 0.02134014666080475, -0.004813270643353462, 0.06140127405524254, -0.10709904134273529, -0.004998167976737022, 0.03104027360677719, 0.01919749565422535, 0.005830214358866215, -0.040238965302705765, 0.001420048763975501, -0.0043757399544119835, 0.030351975932717323, -0.04722236469388008, 0.09378235042095184, 0.0004254042578395456, -0.03960655629634857, -0.019947201013565063, 0.006657011806964874, -0.011834236793220043, -0.013655927032232285, -0.052023954689502716, 0.03737131506204605, -0.0537535585463047, -0.038516815751791, 0.015297042205929756, 0.033193912357091904, -0.00042592332465574145, 0.04208427667617798, 0.032282229512929916, -0.02283627912402153, -0.05866088718175888, 0.005087024997919798, -0.07529543340206146, 0.04661894962191582, 0.061507102102041245, -0.010354074649512768, -0.004280518274754286, -0.05996645241975784, 0.004030450247228146, -0.015417995862662792, -0.019927505403757095, 0.0047317082062363625, 0.00470114778727293, 0.023009169846773148, 0.03317698836326599, 0.009003535844385624, -0.03488614410161972, 0.047599051147699356, -0.0508171021938324, 0.015590825118124485, -0.03355229273438454, -0.013625239953398705, -0.015268104150891304, -0.010445659048855305, 0.041406478732824326, -0.02980884723365307, -0.05800309404730797, -0.02479458414018154, -0.04805587977170944, 0.06632620841264725, -0.03278657793998718, 0.03565727919340134, -0.014457517303526402, 0.0047851987183094025, 0.006611213553696871, -0.003557969816029072, -0.05142012611031532, 0.021597841754555702, -0.02759735658764839, 0.006692448165267706, 0.033692240715026855, -0.03954809904098511, 0.030457137152552605, 0.025992434471845627, 0.02447989583015442, -0.0360005646944046, -0.04010183364152908, 0.011765958741307259, 0.05154206231236458, 0.006095946300774813, -0.0487666130065918, 0.005323311313986778, 0.016538601368665695, 0.02365649864077568, -0.0005270637338981032, 0.041761964559555054, -0.045548442751169205, 0.03023507632315159, -0.05000479519367218, -0.00048722862266004086, -0.031000040471553802, -0.01036432571709156, 0.02464001625776291, 0.013656907714903355, 0.057539138942956924, 0.06455837190151215, -0.03184911981225014, 0.02614973485469818, 0.02790270373225212, -0.0032649626955389977, -0.02879333682358265, -0.02552441507577896, 0.01483344566076994, -0.00018960345187224448, 0.0457904227077961, 0.04190267249941826, -0.035755742341279984, 0.006090101320296526, -0.013227425515651703, -0.023493800312280655, -0.044213488698005676, 0.03660955652594566, -0.06167403981089592, 0.013937936164438725, -0.0010326150804758072, 0.05112356320023537, -0.016887500882148743, 0.0034575629979372025, -0.02990601770579815, -0.0705595389008522, -0.008100619539618492, -0.0605337955057621, -0.009569800458848476, -0.029240349307656288, 0.017358670011162758, -0.004154668189585209, 0.012078647501766682, -0.024082209914922714, -0.04706864804029465, -0.026074351742863655, 0.013392605818808079, -0.026042025536298752, -0.01576646789908409, -0.005262935999780893, -0.013759488239884377, -0.00892641767859459, 0.009842167608439922, 0.048667941242456436, -0.03189360350370407, -0.010280810296535492, 0.027320951223373413, 0.014842788688838482, -0.033012889325618744, -0.0061251139268279076, -0.008735879324376583, -0.027350906282663345, -0.04811348393559456, -0.025131037458777428, -0.020877622067928314, -0.025357723236083984, -0.009832438081502914, 0.045946624130010605, -0.046662334352731705, 0.04938210919499397, 0.010192389599978924, 0.008634629659354687, -0.027182061225175858, 0.037929825484752655, -0.01390437688678503, -0.005754191894084215, 0.06251032650470734, 0.030254090204834938, 0.00089404103346169, -0.025998925790190697, -0.01628311723470688, 0.05147690325975418, 0.03412426635622978, -0.027396289631724358, -0.03387018293142319, 0.02224101684987545, 0.07014686614274979, -0.04109707847237587, -0.03567469120025635, 0.0360606387257576, 0.029423788189888, -0.035055480897426605, 0.017057234421372414, -0.08503030985593796, -0.015151944011449814, 0.03105708584189415, -0.051174428313970566, -0.013508000411093235, 0.02309354767203331, -0.006304576527327299, 0.009756367653608322, 0.0186349805444479, -0.025810446590185165, -0.03210680931806564, -0.010337363928556442, -0.052681125700473785, -0.025844896212220192, -0.001240914803929627, -0.039953283965587616, -0.046087756752967834, 0.01538085751235485, -0.037815988063812256, 0.023303480818867683, 0.017984746024012566, 0.010245749726891518, 0.03241367265582085, -0.04471221938729286, 0.05252876877784729, -0.03831509128212929, 0.026795051991939545, 0.013464308343827724, 0.01772226206958294, 0.01892373524606228, -0.014554182067513466, -0.008409060537815094, -0.08099616318941116, -0.022737249732017517, -0.035057224333286285, 0.016262443736195564, -0.0022878835443407297, 0.053597450256347656, -0.04696971923112869, 0.07587246596813202, 0.06650136411190033, 0.0294958408921957, -0.059841230511665344, 0.03201375529170036, -0.019434144720435143, 0.043793484568595886, -0.05440475791692734, 0.029098449274897575, 0.01919749192893505, -0.016329312697052956, 0.03189148008823395, 0.02045837603509426, -0.045912884175777435, 0.010740400291979313, 0.04079398512840271, -0.07678727060556412, -0.011764229275286198, 0.0037153398152440786, 0.02594490721821785, -0.03624160215258598, -0.0001852941932156682, -0.015782250091433525, -0.03644103184342384, 0.030658481642603874, 0.027561718598008156, -0.00798261258751154, -0.11677209287881851, -0.07838108390569687, -0.003323222277686, 0.013609013520181179, -0.08117423951625824, 0.035634372383356094, -0.014720420353114605, 0.039681389927864075, 0.0004851244739256799, 0.014301822520792484, 0.02402513474225998, 0.03738158941268921, 0.047779329121112823, 0.007399778347462416, 0.0804961770772934, 0.01766437105834484, -0.025654936209321022, -0.0004997979267500341, -0.007486558984965086, 0.016374830156564713, 0.022005511447787285, -0.023427944630384445, -0.0008658752776682377, 0.013448874466121197, -0.024523740634322166, 0.03100409545004368, 0.03380342945456505, -0.08701562881469727, -0.06404171884059906, 0.0033437313977628946, 0.07875268161296844, 0.01939483918249607, -0.005371297709643841, -0.011736988089978695, -0.0028776798862963915, 0.03404214605689049, -0.020984085276722908, -0.0017712299013510346, 0.005153275560587645, -0.007940567098557949, -0.042086318135261536, 0.04105747491121292, -0.04194536432623863, -0.06358816474676132, -0.08175133168697357, 0.04758119583129883, -0.04429902508854866, -0.04962947592139244, 0.009568961337208748, 0.08009093999862671, 0.009888343513011932, -0.037680692970752716, -0.046327754855155945, 0.031298715621232986, 0.02999052032828331, -0.11649967730045319, -0.09387196600437164, -0.02583497203886509, 0.0430203340947628, -0.03256640210747719, -0.036747489124536514, 0.01857583224773407, -0.022167066112160683, -0.02113906480371952, 0.034815188497304916, -0.0855879932641983, -0.021023059263825417, 0.00357545493170619, 0.038693442940711975, 0.027222348377108574, 0.01588776521384716, 0.0014050804311409593, -0.0057579511776566505, -0.09496753662824631, 0.029192345216870308, -0.05168696492910385, 0.05922204256057739, -0.0421244241297245, -0.0439467653632164, 0.011194020509719849, -0.06738012284040451, -0.03270426020026207, -0.03496700897812843, 0.07989226281642914, 0.008473283611238003, -0.027478091418743134, 0.009218242019414902, -0.02449929714202881, 0.013025593012571335, 0.006422656588256359, 0.02490304969251156, -0.018438661471009254, -0.008979163132607937, 0.014364359900355339, 0.01775355264544487, -0.02982785552740097, -0.01918136700987816, -0.0166019219905138, 0.02042986825108528, -0.020916905254125595, 0.008269120939075947, 0.005885526537895203, 0.013531609438359737, 0.011418682523071766, 0.019101034849882126, 0.007808696012943983, -0.021167941391468048, 0.06588874012231827, 0.025251328945159912, 0.0030808637384325266, -0.006742026191204786, 0.013751945458352566, 0.06873705238103867, -0.02480302006006241, -0.00039861450204625726, -0.012084854766726494, -0.05125662311911583, 0.06091511994600296, 0.00885255727916956, -0.011709053069353104, -0.01369162555783987, -0.09074164927005768, 0.00650453008711338, -0.01852564513683319, 0.02493143081665039, 0.02458404004573822, -0.03418659791350365, -0.012069675140082836, 0.02972322888672352, -0.017488114535808563, 0.04502009227871895, 0.0019106619292870164, -0.015934856608510017, -0.016649894416332245, 0.04499336704611778, -0.03363994136452675, -0.07565248012542725, 0.07677709311246872, 0.027235301211476326, -0.018004706129431725, -0.03168882429599762, -0.029420292004942894, -0.01904001273214817, 0.05954771488904953, 0.029031502082943916, 0.012872785329818726, -0.005862645339220762, 0.02094864286482334, 0.014992783777415752, -0.026760729029774666, 0.007458177395164967, 0.013883069157600403, 0.02613651752471924, 0.07557068765163422, 0.05685577169060707, 0.03493247181177139, -0.05375167354941368, 0.027821894735097885, -0.002621453022584319, 0.009951945394277573, 0.06372544914484024, -0.010834315791726112, -0.048843786120414734, -6.57585131503419e-33, -0.018727807328104973, -0.026378128677606583, -0.008825663477182388, 0.043211694806814194, -0.011037623509764671, -0.03182123228907585, 0.027261342853307724, 0.04719933122396469, 0.01568037085235119, -0.02643846534192562, -0.005570404697209597, 0.016527852043509483, 0.01572256349027157, -0.007679393980652094, 0.048344165086746216, -0.006221710704267025, 0.06671582907438278, 0.005410932470113039, -0.00046685055713169277, -0.008392672054469585, -0.032342784106731415, -0.025025127455592155, 0.010641810484230518, -0.003300674259662628, -0.004973028786480427, 0.07916028797626495, -0.014858231879770756, -0.009459530003368855, 0.042438361793756485, 0.00872894749045372, 0.012375426478683949, 0.023515619337558746, -0.023176664486527443, 0.08363069593906403, -0.004091983195394278, 0.022349881008267403, -0.022341646254062653, -0.045661117881536484, -0.03238058462738991, 0.0014136673416942358, -0.004945532884448767, -0.06800588965415955, 0.07647783309221268, -0.028833890333771706, 0.00165404356084764, -0.03413207828998566, 0.05528976023197174, -0.008957846090197563, 0.06273799389600754, -0.009352307766675949, -0.05560417100787163, 0.0013196691870689392, -0.06871584057807922, -0.025803783908486366, 0.007489404641091824, -0.09854598343372345, 0.054543282836675644, 0.0001455430028727278, -0.004838563967496157, 0.043878551572561264, -0.03404546156525612, 0.021690480411052704, -0.02626216597855091, -0.0029000043869018555, 0.006992335431277752, 0.009076282382011414, 0.07943841069936752, 0.003931026440113783, 0.014002359472215176, 0.08618728816509247, 0.011754738166928291, 0.03903926536440849, 0.010368292219936848, 0.03498253598809242, 0.03369910269975662, -0.05290665104985237, -0.023097112774848938, -0.0007343890611082315, -0.060828570276498795, -0.020987030118703842, 0.005217548925429583, 0.026725780218839645, -0.006606708280742168, -0.03753398731350899, 0.07492545247077942, 0.0024529777001589537, -0.0105771254748106, 0.0018746843561530113, -0.047276947647333145, 0.0293106772005558, 0.014977581799030304, 0.02413112297654152, -0.0206019077450037, -0.011674251407384872, 0.015910333022475243, 0.02948828414082527, -0.025318030267953873, 0.03691510111093521, -0.022213676944375038, -0.018493102863430977, 0.024656539782881737, 0.010742348618805408, -0.007684546522796154, -0.033385470509529114, 0.034495383501052856, 0.01653408072888851, -0.019618166610598564, 0.013713917694985867, 0.00025158014614135027, -0.016529645770788193, -0.01828000880777836, 0.010103225708007812, 0.06321084499359131, 0.028778506442904472, 0.04461602866649628, -0.0022679544053971767, 0.02823236584663391, -0.043433934450149536, -0.0580972321331501, -0.044721122831106186, -0.036401551216840744, -0.026860881596803665, -0.056323446333408356, 0.02298581227660179, 0.002940655453130603, -0.04837541654706001, -0.05172295123338699, 0.015475613996386528, 0.0015420104609802365, -0.01964982971549034, -0.024930516257882118, 0.009146804921329021, 2.2893020457104285e-07, 0.01050429604947567, 0.0445575937628746, -0.012117850594222546, 0.07725510001182556, 0.011911305598914623, 0.022133326157927513, -0.02440454065799713, 0.017086312174797058, 0.010007388889789581, 0.017389733344316483, -0.06254792213439941, 0.02040645107626915, 0.05484340339899063, -0.0018058388959616423, -0.0046567232348024845, 0.004003376234322786, 0.0443679615855217, 0.0017643673345446587, 0.007991486229002476, -0.008096118457615376, 0.10006806999444962, 0.02293204329907894, 0.06573460251092911, 0.013270551338791847, 0.02744591049849987, 0.010599168948829174, 0.01420672982931137, -0.042726900428533554, 0.11296803504228592, 0.03061257302761078, -0.1074194386601448, 0.03578902408480644, 0.00024448969634249806, 0.004007160197943449, -0.010912668891251087, -0.09249882400035858, 0.03865938261151314, 0.03210792317986488, 0.030704855918884277, 0.0801999494433403, -0.0349934846162796, 0.010253729298710823, -0.030437255278229713, -0.007403282914310694, -0.0034079025499522686, 0.011447424069046974, 0.03963613510131836, 0.023638607934117317, -0.00414345134049654, -0.020931370556354523, -0.026715870946645737, -0.01474079955369234, 0.017961623147130013, -0.020756276324391365, -0.002672639675438404, -0.022115537896752357, -0.023630734533071518, 0.02134062349796295, 0.005591946188360453, 0.011902746744453907, -0.04753683879971504, -0.00219096802175045, 0.013217215426266193, 0.038700152188539505, 0.08060214668512344, 0.020989399403333664, 0.006108321249485016, 1.5076311980020864e-34, 0.013684089295566082, -0.027184635400772095, -0.007269466761499643, 0.04452819377183914, 0.03245333209633827, -0.0010396792786195874, 0.010292352177202702, -0.013185882940888405, 0.005942948628216982, 0.03976302221417427, -0.04407054930925369]\n",
            "query_result length: 768\n",
            "document_result: [-0.029304862022399902, 0.06239829212427139, -0.064301036298275, 0.014795470051467419, 0.01879589818418026, 0.0608164444565773, -0.07478100061416626, -0.01659526117146015, -0.030508002266287804, 0.030598340556025505, 0.025639722123742104, 0.038709282875061035, 0.0024956215638667345, 0.1047094389796257, 0.009299385361373425, 0.01294324453920126, -0.022103862836956978, -0.022564884275197983, -0.03605072572827339, 0.00011076000373577699, 0.02002040110528469, 0.03963882476091385, -0.042874306440353394, -0.02453198842704296, -0.004480579402297735, -0.009060772135853767, 0.009875593706965446, -0.06069997325539589, -0.03463570773601532, 0.05754446983337402, -0.002160274889320135, -0.0021566080395132303, -0.005808633752167225, 0.0028201164677739143, 1.6196588603634154e-06, 0.004496601410210133, -0.015027355402708054, -0.002435229951515794, -0.05663324519991875, 0.02231852523982525, -0.030137047171592712, -0.021930424496531487, -0.02272447571158409, 0.007798372767865658, -0.0473465621471405, 0.023754384368658066, 0.0917426347732544, -0.05870368704199791, 0.029528871178627014, 0.00017409477732144296, -0.004552232567220926, -0.016986533999443054, -0.017124490812420845, -0.022883981466293335, 0.019126415252685547, 0.033929698169231415, 0.01704089716076851, 0.05406181514263153, 0.09688348323106766, 0.010747317224740982, -0.02364988997578621, -0.047129202634096146, 0.04012304171919823, 0.01001310721039772, 0.07217058539390564, 0.05043113976716995, 0.003910656087100506, -0.02521788515150547, 0.028067052364349365, 0.021775998175144196, 0.009601669386029243, -0.03881899267435074, -0.002839385299012065, 0.02536410093307495, 0.019633812829852104, -0.07761761546134949, -0.03287467733025551, 0.0472879596054554, 0.0025174091570079327, -0.01160526368767023, -0.006696982774883509, 0.008956176228821278, -0.008238988928496838, -0.02282298356294632, 0.009934370405972004, -0.0283819492906332, 0.0003002817975357175, -0.019606273621320724, -0.04657846316695213, 0.06873288750648499, 0.003942378330975771, -0.017649900168180466, 0.03996951878070831, 0.055884163826704025, -0.023013940081000328, 0.004712925758212805, -0.008467601612210274, 0.018591998144984245, 0.0064796824008226395, 0.024042172357439995, 0.002820840571075678, 0.045340172946453094, -0.007313026115298271, 0.02072312869131565, -0.019276544451713562, 0.01033987756818533, 0.01413769368082285, -0.002880614250898361, -0.0003788950853049755, 0.05597872659564018, -0.056972354650497437, -0.03653380274772644, 0.009467170573771, 0.028701959177851677, 0.010220987722277641, 0.08910344541072845, 0.01534245628863573, 0.06612782180309296, 0.007736260537058115, 0.01912735402584076, -0.017602108418941498, 0.004523506388068199, 0.013643178157508373, 0.059951893985271454, 0.04139655455946922, -0.062391169369220734, -0.04053959622979164, 0.004351409617811441, -0.043168794363737106, -0.010091309435665607, -0.03326224163174629, -0.012742179445922375, -0.0008257169974967837, -0.04352286085486412, -0.0007254367228597403, 0.02952035516500473, -0.06073034927248955, 0.02683776244521141, 0.04452318698167801, -0.03760207071900368, -0.007658577058464289, 0.003347768448293209, 0.02004939690232277, -0.03437725082039833, 0.02030937746167183, 0.008979144506156445, -0.007191873155534267, -0.0546085424721241, -0.00751173822209239, 0.02134014666080475, -0.004813270643353462, 0.06140127405524254, -0.10709904134273529, -0.004998167976737022, 0.03104027360677719, 0.01919749565422535, 0.005830214358866215, -0.040238965302705765, 0.001420048763975501, -0.0043757399544119835, 0.030351975932717323, -0.04722236469388008, 0.09378235042095184, 0.0004254042578395456, -0.03960655629634857, -0.019947201013565063, 0.006657011806964874, -0.011834236793220043, -0.013655927032232285, -0.052023954689502716, 0.03737131506204605, -0.0537535585463047, -0.038516815751791, 0.015297042205929756, 0.033193912357091904, -0.00042592332465574145, 0.04208427667617798, 0.032282229512929916, -0.02283627912402153, -0.05866088718175888, 0.005087024997919798, -0.07529543340206146, 0.04661894962191582, 0.061507102102041245, -0.010354074649512768, -0.004280518274754286, -0.05996645241975784, 0.004030450247228146, -0.015417995862662792, -0.019927505403757095, 0.0047317082062363625, 0.00470114778727293, 0.023009169846773148, 0.03317698836326599, 0.009003535844385624, -0.03488614410161972, 0.047599051147699356, -0.0508171021938324, 0.015590825118124485, -0.03355229273438454, -0.013625239953398705, -0.015268104150891304, -0.010445659048855305, 0.041406478732824326, -0.02980884723365307, -0.05800309404730797, -0.02479458414018154, -0.04805587977170944, 0.06632620841264725, -0.03278657793998718, 0.03565727919340134, -0.014457517303526402, 0.0047851987183094025, 0.006611213553696871, -0.003557969816029072, -0.05142012611031532, 0.021597841754555702, -0.02759735658764839, 0.006692448165267706, 0.033692240715026855, -0.03954809904098511, 0.030457137152552605, 0.025992434471845627, 0.02447989583015442, -0.0360005646944046, -0.04010183364152908, 0.011765958741307259, 0.05154206231236458, 0.006095946300774813, -0.0487666130065918, 0.005323311313986778, 0.016538601368665695, 0.02365649864077568, -0.0005270637338981032, 0.041761964559555054, -0.045548442751169205, 0.03023507632315159, -0.05000479519367218, -0.00048722862266004086, -0.031000040471553802, -0.01036432571709156, 0.02464001625776291, 0.013656907714903355, 0.057539138942956924, 0.06455837190151215, -0.03184911981225014, 0.02614973485469818, 0.02790270373225212, -0.0032649626955389977, -0.02879333682358265, -0.02552441507577896, 0.01483344566076994, -0.00018960345187224448, 0.0457904227077961, 0.04190267249941826, -0.035755742341279984, 0.006090101320296526, -0.013227425515651703, -0.023493800312280655, -0.044213488698005676, 0.03660955652594566, -0.06167403981089592, 0.013937936164438725, -0.0010326150804758072, 0.05112356320023537, -0.016887500882148743, 0.0034575629979372025, -0.02990601770579815, -0.0705595389008522, -0.008100619539618492, -0.0605337955057621, -0.009569800458848476, -0.029240349307656288, 0.017358670011162758, -0.004154668189585209, 0.012078647501766682, -0.024082209914922714, -0.04706864804029465, -0.026074351742863655, 0.013392605818808079, -0.026042025536298752, -0.01576646789908409, -0.005262935999780893, -0.013759488239884377, -0.00892641767859459, 0.009842167608439922, 0.048667941242456436, -0.03189360350370407, -0.010280810296535492, 0.027320951223373413, 0.014842788688838482, -0.033012889325618744, -0.0061251139268279076, -0.008735879324376583, -0.027350906282663345, -0.04811348393559456, -0.025131037458777428, -0.020877622067928314, -0.025357723236083984, -0.009832438081502914, 0.045946624130010605, -0.046662334352731705, 0.04938210919499397, 0.010192389599978924, 0.008634629659354687, -0.027182061225175858, 0.037929825484752655, -0.01390437688678503, -0.005754191894084215, 0.06251032650470734, 0.030254090204834938, 0.00089404103346169, -0.025998925790190697, -0.01628311723470688, 0.05147690325975418, 0.03412426635622978, -0.027396289631724358, -0.03387018293142319, 0.02224101684987545, 0.07014686614274979, -0.04109707847237587, -0.03567469120025635, 0.0360606387257576, 0.029423788189888, -0.035055480897426605, 0.017057234421372414, -0.08503030985593796, -0.015151944011449814, 0.03105708584189415, -0.051174428313970566, -0.013508000411093235, 0.02309354767203331, -0.006304576527327299, 0.009756367653608322, 0.0186349805444479, -0.025810446590185165, -0.03210680931806564, -0.010337363928556442, -0.052681125700473785, -0.025844896212220192, -0.001240914803929627, -0.039953283965587616, -0.046087756752967834, 0.01538085751235485, -0.037815988063812256, 0.023303480818867683, 0.017984746024012566, 0.010245749726891518, 0.03241367265582085, -0.04471221938729286, 0.05252876877784729, -0.03831509128212929, 0.026795051991939545, 0.013464308343827724, 0.01772226206958294, 0.01892373524606228, -0.014554182067513466, -0.008409060537815094, -0.08099616318941116, -0.022737249732017517, -0.035057224333286285, 0.016262443736195564, -0.0022878835443407297, 0.053597450256347656, -0.04696971923112869, 0.07587246596813202, 0.06650136411190033, 0.0294958408921957, -0.059841230511665344, 0.03201375529170036, -0.019434144720435143, 0.043793484568595886, -0.05440475791692734, 0.029098449274897575, 0.01919749192893505, -0.016329312697052956, 0.03189148008823395, 0.02045837603509426, -0.045912884175777435, 0.010740400291979313, 0.04079398512840271, -0.07678727060556412, -0.011764229275286198, 0.0037153398152440786, 0.02594490721821785, -0.03624160215258598, -0.0001852941932156682, -0.015782250091433525, -0.03644103184342384, 0.030658481642603874, 0.027561718598008156, -0.00798261258751154, -0.11677209287881851, -0.07838108390569687, -0.003323222277686, 0.013609013520181179, -0.08117423951625824, 0.035634372383356094, -0.014720420353114605, 0.039681389927864075, 0.0004851244739256799, 0.014301822520792484, 0.02402513474225998, 0.03738158941268921, 0.047779329121112823, 0.007399778347462416, 0.0804961770772934, 0.01766437105834484, -0.025654936209321022, -0.0004997979267500341, -0.007486558984965086, 0.016374830156564713, 0.022005511447787285, -0.023427944630384445, -0.0008658752776682377, 0.013448874466121197, -0.024523740634322166, 0.03100409545004368, 0.03380342945456505, -0.08701562881469727, -0.06404171884059906, 0.0033437313977628946, 0.07875268161296844, 0.01939483918249607, -0.005371297709643841, -0.011736988089978695, -0.0028776798862963915, 0.03404214605689049, -0.020984085276722908, -0.0017712299013510346, 0.005153275560587645, -0.007940567098557949, -0.042086318135261536, 0.04105747491121292, -0.04194536432623863, -0.06358816474676132, -0.08175133168697357, 0.04758119583129883, -0.04429902508854866, -0.04962947592139244, 0.009568961337208748, 0.08009093999862671, 0.009888343513011932, -0.037680692970752716, -0.046327754855155945, 0.031298715621232986, 0.02999052032828331, -0.11649967730045319, -0.09387196600437164, -0.02583497203886509, 0.0430203340947628, -0.03256640210747719, -0.036747489124536514, 0.01857583224773407, -0.022167066112160683, -0.02113906480371952, 0.034815188497304916, -0.0855879932641983, -0.021023059263825417, 0.00357545493170619, 0.038693442940711975, 0.027222348377108574, 0.01588776521384716, 0.0014050804311409593, -0.0057579511776566505, -0.09496753662824631, 0.029192345216870308, -0.05168696492910385, 0.05922204256057739, -0.0421244241297245, -0.0439467653632164, 0.011194020509719849, -0.06738012284040451, -0.03270426020026207, -0.03496700897812843, 0.07989226281642914, 0.008473283611238003, -0.027478091418743134, 0.009218242019414902, -0.02449929714202881, 0.013025593012571335, 0.006422656588256359, 0.02490304969251156, -0.018438661471009254, -0.008979163132607937, 0.014364359900355339, 0.01775355264544487, -0.02982785552740097, -0.01918136700987816, -0.0166019219905138, 0.02042986825108528, -0.020916905254125595, 0.008269120939075947, 0.005885526537895203, 0.013531609438359737, 0.011418682523071766, 0.019101034849882126, 0.007808696012943983, -0.021167941391468048, 0.06588874012231827, 0.025251328945159912, 0.0030808637384325266, -0.006742026191204786, 0.013751945458352566, 0.06873705238103867, -0.02480302006006241, -0.00039861450204625726, -0.012084854766726494, -0.05125662311911583, 0.06091511994600296, 0.00885255727916956, -0.011709053069353104, -0.01369162555783987, -0.09074164927005768, 0.00650453008711338, -0.01852564513683319, 0.02493143081665039, 0.02458404004573822, -0.03418659791350365, -0.012069675140082836, 0.02972322888672352, -0.017488114535808563, 0.04502009227871895, 0.0019106619292870164, -0.015934856608510017, -0.016649894416332245, 0.04499336704611778, -0.03363994136452675, -0.07565248012542725, 0.07677709311246872, 0.027235301211476326, -0.018004706129431725, -0.03168882429599762, -0.029420292004942894, -0.01904001273214817, 0.05954771488904953, 0.029031502082943916, 0.012872785329818726, -0.005862645339220762, 0.02094864286482334, 0.014992783777415752, -0.026760729029774666, 0.007458177395164967, 0.013883069157600403, 0.02613651752471924, 0.07557068765163422, 0.05685577169060707, 0.03493247181177139, -0.05375167354941368, 0.027821894735097885, -0.002621453022584319, 0.009951945394277573, 0.06372544914484024, -0.010834315791726112, -0.048843786120414734, -6.57585131503419e-33, -0.018727807328104973, -0.026378128677606583, -0.008825663477182388, 0.043211694806814194, -0.011037623509764671, -0.03182123228907585, 0.027261342853307724, 0.04719933122396469, 0.01568037085235119, -0.02643846534192562, -0.005570404697209597, 0.016527852043509483, 0.01572256349027157, -0.007679393980652094, 0.048344165086746216, -0.006221710704267025, 0.06671582907438278, 0.005410932470113039, -0.00046685055713169277, -0.008392672054469585, -0.032342784106731415, -0.025025127455592155, 0.010641810484230518, -0.003300674259662628, -0.004973028786480427, 0.07916028797626495, -0.014858231879770756, -0.009459530003368855, 0.042438361793756485, 0.00872894749045372, 0.012375426478683949, 0.023515619337558746, -0.023176664486527443, 0.08363069593906403, -0.004091983195394278, 0.022349881008267403, -0.022341646254062653, -0.045661117881536484, -0.03238058462738991, 0.0014136673416942358, -0.004945532884448767, -0.06800588965415955, 0.07647783309221268, -0.028833890333771706, 0.00165404356084764, -0.03413207828998566, 0.05528976023197174, -0.008957846090197563, 0.06273799389600754, -0.009352307766675949, -0.05560417100787163, 0.0013196691870689392, -0.06871584057807922, -0.025803783908486366, 0.007489404641091824, -0.09854598343372345, 0.054543282836675644, 0.0001455430028727278, -0.004838563967496157, 0.043878551572561264, -0.03404546156525612, 0.021690480411052704, -0.02626216597855091, -0.0029000043869018555, 0.006992335431277752, 0.009076282382011414, 0.07943841069936752, 0.003931026440113783, 0.014002359472215176, 0.08618728816509247, 0.011754738166928291, 0.03903926536440849, 0.010368292219936848, 0.03498253598809242, 0.03369910269975662, -0.05290665104985237, -0.023097112774848938, -0.0007343890611082315, -0.060828570276498795, -0.020987030118703842, 0.005217548925429583, 0.026725780218839645, -0.006606708280742168, -0.03753398731350899, 0.07492545247077942, 0.0024529777001589537, -0.0105771254748106, 0.0018746843561530113, -0.047276947647333145, 0.0293106772005558, 0.014977581799030304, 0.02413112297654152, -0.0206019077450037, -0.011674251407384872, 0.015910333022475243, 0.02948828414082527, -0.025318030267953873, 0.03691510111093521, -0.022213676944375038, -0.018493102863430977, 0.024656539782881737, 0.010742348618805408, -0.007684546522796154, -0.033385470509529114, 0.034495383501052856, 0.01653408072888851, -0.019618166610598564, 0.013713917694985867, 0.00025158014614135027, -0.016529645770788193, -0.01828000880777836, 0.010103225708007812, 0.06321084499359131, 0.028778506442904472, 0.04461602866649628, -0.0022679544053971767, 0.02823236584663391, -0.043433934450149536, -0.0580972321331501, -0.044721122831106186, -0.036401551216840744, -0.026860881596803665, -0.056323446333408356, 0.02298581227660179, 0.002940655453130603, -0.04837541654706001, -0.05172295123338699, 0.015475613996386528, 0.0015420104609802365, -0.01964982971549034, -0.024930516257882118, 0.009146804921329021, 2.2893020457104285e-07, 0.01050429604947567, 0.0445575937628746, -0.012117850594222546, 0.07725510001182556, 0.011911305598914623, 0.022133326157927513, -0.02440454065799713, 0.017086312174797058, 0.010007388889789581, 0.017389733344316483, -0.06254792213439941, 0.02040645107626915, 0.05484340339899063, -0.0018058388959616423, -0.0046567232348024845, 0.004003376234322786, 0.0443679615855217, 0.0017643673345446587, 0.007991486229002476, -0.008096118457615376, 0.10006806999444962, 0.02293204329907894, 0.06573460251092911, 0.013270551338791847, 0.02744591049849987, 0.010599168948829174, 0.01420672982931137, -0.042726900428533554, 0.11296803504228592, 0.03061257302761078, -0.1074194386601448, 0.03578902408480644, 0.00024448969634249806, 0.004007160197943449, -0.010912668891251087, -0.09249882400035858, 0.03865938261151314, 0.03210792317986488, 0.030704855918884277, 0.0801999494433403, -0.0349934846162796, 0.010253729298710823, -0.030437255278229713, -0.007403282914310694, -0.0034079025499522686, 0.011447424069046974, 0.03963613510131836, 0.023638607934117317, -0.00414345134049654, -0.020931370556354523, -0.026715870946645737, -0.01474079955369234, 0.017961623147130013, -0.020756276324391365, -0.002672639675438404, -0.022115537896752357, -0.023630734533071518, 0.02134062349796295, 0.005591946188360453, 0.011902746744453907, -0.04753683879971504, -0.00219096802175045, 0.013217215426266193, 0.038700152188539505, 0.08060214668512344, 0.020989399403333664, 0.006108321249485016, 1.5076311980020864e-34, 0.013684089295566082, -0.027184635400772095, -0.007269466761499643, 0.04452819377183914, 0.03245333209633827, -0.0010396792786195874, 0.010292352177202702, -0.013185882940888405, 0.005942948628216982, 0.03976302221417427, -0.04407054930925369]\n",
            "document_result length: 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part3 : Cosine similarity\n",
        "Cosine similarity is a mathematical measure used to determine how similar two vectors are, regardless of their magnitude. In the context of Retrieval-Augmented Generation (RAG) , cosine similarity plays a crucial role in retrieving relevant information from a knowledge base or corpus before generating responses.\n",
        "\n",
        "---\n",
        "\n",
        "- **Mathematical Formula**:  \n",
        "   The cosine similarity between two vectors $ A $ and $ B $ is given by:\n",
        "   $$\n",
        "   \\text{Cosine Similarity}(A, B) = \\cos(\\theta) = \\frac{A \\cdot B}{\\|A\\| \\|B\\|}\n",
        "   $$\n",
        "   Where:\n",
        "   - $ A \\cdot B $ is the dot product of $ A $ and $ B $: $ A \\cdot B = \\sum_{i=1}^n A_i B_i $\n",
        "   - $ \\|A\\| $ and $ \\|B\\| $ are the magnitudes (or Euclidean norms) of $ A $ and $ B $, respectively:\n",
        "\n",
        "    $$\n",
        "    \\|A\\| = \\sqrt{\\sum_{i=1}^n A_i^2}, \\quad \\|B\\| = \\sqrt{\\sum_{i=1}^n B_i^2} $$\n",
        "---\n",
        "### **Key Properties**\n",
        "1. **Range**:  \n",
        "   - Ranges from **-1 to 1** (but **0 to 1** for non-negative vectors, e.g., TF-IDF document vectors).  \n",
        "   - **1**: Vectors are identical in direction.  \n",
        "   - **0**: Vectors are orthogonal (no similarity).  \n",
        "   - **-1**: Vectors are diametrically opposed.\n",
        "\n",
        "2. **Magnitude Invariance**:  \n",
        "   - Focuses on orientation, not magnitude. Useful when comparing objects where size differences are irrelevant (e.g., text documents of varying lengths).\n",
        "---\n",
        "### **Example Calculation**\n",
        "For vectors $ \\mathbf{A} = [1, 2] $ and $ \\mathbf{B} = [2, 1] :$  \n",
        "1. **Dot Product**:$ (1 \\times 2) + (2 \\times 1) = 4 . $\n",
        "2. **Magnitudes**: $ \\|\\mathbf{A}\\| = \\sqrt{1^2 + 2^2} = \\sqrt{5} ,  \\|\\mathbf{B}\\| = \\sqrt{2^2 + 1^2} = \\sqrt{5} .  $\n",
        "3. **Cosine Similarity**: $ \\frac{4}{\\sqrt{5} \\times \\sqrt{5}} = \\frac{4}{5} = 0.8 . $\n"
      ],
      "metadata": {
        "id": "_bMRjEZKOoQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    dot_product = np.dot(vec1, vec2)\n",
        "    norm_vec1 = np.linalg.norm(vec1)\n",
        "    norm_vec2 = np.linalg.norm(vec2)\n",
        "    return dot_product / (norm_vec1 * norm_vec2)\n",
        "\n",
        "similarity = cosine_similarity(query_result, document_result)\n",
        "print(\"Cosine Similarity:\", similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtDxn90UOiKC",
        "outputId": "df08c378-a4fb-43f7-8e9a-62e44570e159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5 : Loader"
      ],
      "metadata": {
        "id": "tvXOMrAnRk-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### INDEXING ####\n",
        "\n",
        "# Loading blog\n",
        "import bs4\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "blog_docs = loader.load()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkamzqkaRoB-",
        "outputId": "b984dce5-14f8-4477-b2e9-c8edceeaec1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blog_docs"
      ],
      "metadata": {
        "id": "-vpND8lFRwyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 6 : [**Text Splitter**](https://python.langchain.com/docs/how_to/recursive_text_splitter/)\n",
        "\n",
        "\n",
        "\n",
        "> This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is [\"\\n\\n\", \"\\n\", \" \", \"\"]. This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f_KKFRMqSUZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=50)\n",
        "\n",
        "# Make splits\n",
        "splits = text_splitter.split_documents(blog_docs)"
      ],
      "metadata": {
        "id": "dzYLo5lZTF8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaTBNBoKTHog",
        "outputId": "b8ec7348-16b9-4652-a1f9-339eaf54c596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 7 : Vectorstore"
      ],
      "metadata": {
        "id": "cyZsjJZTTzeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "id": "02kcJJg_UHm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "vectorstore = Chroma.from_documents(documents=splits,\n",
        "                                    embedding=HuggingFaceEmbeddings())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFUXT1DIT_E5",
        "outputId": "a0bbf2ce-c6a0-4f15-ee2a-d4b66b9d35b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-dd0ac9e1ebd2>:3: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
            "  embedding=HuggingFaceEmbeddings())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})"
      ],
      "metadata": {
        "id": "-BbrPqEzU5S5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = retriever.get_relevant_documents(\"What is Task Decomposition?\")"
      ],
      "metadata": {
        "id": "mF2mOkxOUtjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9TV7f_CVXUc",
        "outputId": "0fab5088-fab1-4ea5-a9e9-e8289a9bc60b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKFTF9dIUu1Y",
        "outputId": "72c38332-1125-47e9-8ad3-c580ca6be63d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:')"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3THSM2k2VKgV",
        "outputId": "d2e73da5-db8f-4c38-f030-04de1bbf0183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 8: Generation\n",
        "![](https://iili.io/3JCzBQn.png)"
      ],
      "metadata": {
        "id": "VzpnIV5fVuuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# Prompt\n",
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCeK_r3qV1RC",
        "outputId": "d5857d00-1f39-418b-ca83-2981760f845e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based only on the following context:\\n{context}\\n\\nQuestion: {question}\\n'), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-huggingface"
      ],
      "metadata": {
        "id": "-o77zrMeXG0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "# LLM\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=\"deepseek-ai/DeepSeek-R1\",\n",
        "     temperature=0.2 #@param {\"type\":\"number\",\"placeholder\":\"0.7\"}\n",
        "    ,\n",
        "    max_length=512,\n",
        "    task='text-generation',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBOMO8D5Wdlw",
        "outputId": "490836dc-316b-4439-b4a3-6ef5e55ac386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_huggingface.llms.huggingface_endpoint:WARNING! max_length is not default parameter.\n",
            "                    max_length was transferred to model_kwargs.\n",
            "                    Please make sure that max_length is what you intended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain\n",
        "\n",
        "chain = prompt | llm #chain pipeline\n",
        "\n",
        "# ### without pipeline\n",
        "# input=prompt.format_prompt(context=docs[0].page_content, question=\"What is Task Decomposition?\")\n",
        "# response=llm.invoke(input)\n",
        "# response"
      ],
      "metadata": {
        "id": "uWoIGcVhXxGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run\n",
        "chain.invoke({\"context\":lambda docs: \"\\n\\n\".join(d.page_content for d in docs|),\n",
        "                                                 \"question\":\"What is Task Decomposition?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "uirDvx7WZ4gd",
        "outputId": "278815c0-313d-43b5-fc38-d336ec38e1db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Answer: Task Decomposition is the process of breaking down a complex task into smaller, more manageable steps or subgoals. This can be done by a Large Language Model (LLM) using simple prompts, task-specific instructions, or with human inputs.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "prompt_hub_rag = hub.pull(\"rlm/rag-prompt\") #@markdown create a langsmith acount here [**smith.langchain.com**](https://smith.langchain.com/) then generate langsmith API key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGABtIoNankX",
        "outputId": "dcae5cc0-c14c-4850-dadf-cc0d99ad278c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_hub_rag"
      ],
      "metadata": {
        "id": "du0xRVHIb7c3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [**RAG chains**]()"
      ],
      "metadata": {
        "id": "JpD3Wq84cAry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "\n",
        "rag_chain = (\n",
        "    {\n",
        "        \"context\": retriever | (lambda docs: \"\\n\\n\".join(d.page_content for d in docs)),\n",
        "        \"question\": RunnablePassthrough()\n",
        "    }\n",
        "    | prompt_hub_rag\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "rag_chain.invoke(\"What is Task Decomposition?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "qiAcXfr0clNf",
        "outputId": "5870300d-64fd-475c-f025-cc6a5731ff7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Answer: Task Decomposition is the process of breaking down a complex task into smaller, more manageable subtasks. This can be done by the LLM with simple prompting, using task-specific instructions, or with human inputs. The goal is to transform big tasks into multiple manageable tasks to make them easier to understand and execute.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaimoKrU4kG7"
      },
      "source": [
        "# Installing Required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjhXLrM5D2tP",
        "outputId": "f78bc6fc-706c-46d4-d51d-6d8e736344af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.3.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting langchain-experimental\n",
            "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.2.4-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.18-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting unstructured[all]\n",
            "  Downloading unstructured-0.16.23-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.37)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.28.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Collecting groq<1,>=0.4.1 (from langchain-groq)\n",
            "  Downloading groq-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.8.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "\u001b[33mWARNING: unstructured 0.16.23 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from unstructured[all]) (5.2.0)\n",
            "Collecting filetype (from unstructured[all])\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting python-magic (from unstructured[all])\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from unstructured[all]) (5.3.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from unstructured[all]) (3.9.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from unstructured[all]) (4.13.3)\n",
            "Collecting emoji (from unstructured[all])\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting python-iso639 (from unstructured[all])\n",
            "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting langdetect (from unstructured[all])\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rapidfuzz (from unstructured[all])\n",
            "  Downloading rapidfuzz-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting backoff (from unstructured[all])\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from unstructured[all]) (4.12.2)\n",
            "Collecting unstructured-client (from unstructured[all])\n",
            "  Downloading unstructured_client-0.30.4-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from unstructured[all]) (1.17.2)\n",
            "Collecting python-oxmsg (from unstructured[all])\n",
            "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.11/dist-packages (from unstructured[all]) (1.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->unstructured[all]) (2.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.11/dist-packages (from html5lib->unstructured[all]) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from html5lib->unstructured[all]) (0.5.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured[all]) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured[all]) (1.4.2)\n",
            "Collecting olefile (from python-oxmsg->unstructured[all])\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured[all])\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: cryptography>=3.1 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured[all]) (43.0.3)\n",
            "Collecting eval-type-backport>=0.2.0 (from unstructured-client->unstructured[all])\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured[all]) (1.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured[all]) (2.8.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.1->unstructured-client->unstructured[all]) (1.17.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured[all]) (2.22)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.3.0-py3-none-any.whl (300 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.7/300.7 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-0.2.4-py3-none-any.whl (14 kB)\n",
            "Downloading langchain_community-0.3.18-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading groq-0.18.0-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.8.0-py3-none-any.whl (30 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m906.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
            "Downloading rapidfuzz-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured-0.16.23-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured_client-0.30.4-py3-none-any.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=562da6db33becb0a075dc871267a3a3689e60b5b8835129eb1b31b618c6c6702\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "Successfully built langdetect\n",
            "Installing collected packages: filetype, rapidfuzz, python-magic, python-iso639, python-dotenv, pypdf, olefile, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, marshmallow, langdetect, httpx-sse, faiss-cpu, eval-type-backport, emoji, backoff, aiofiles, typing-inspect, python-oxmsg, nvidia-cusparse-cu12, nvidia-cudnn-cu12, unstructured-client, pydantic-settings, nvidia-cusolver-cu12, groq, dataclasses-json, unstructured, langchain-groq, langchain-community, langchain-experimental\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed aiofiles-24.1.0 backoff-2.2.1 dataclasses-json-0.6.7 emoji-2.14.1 eval-type-backport-0.2.2 faiss-cpu-1.10.0 filetype-1.2.0 groq-0.18.0 httpx-sse-0.4.0 langchain-community-0.3.18 langchain-experimental-0.3.4 langchain-groq-0.2.4 langdetect-1.0.9 marshmallow-3.26.1 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 olefile-0.47 pydantic-settings-2.8.0 pypdf-5.3.0 python-dotenv-1.0.1 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 rapidfuzz-3.12.1 typing-inspect-0.9.0 unstructured-0.16.23 unstructured-client-0.30.4\n"
          ]
        }
      ],
      "source": [
        "#@title <b>Installing Required packages</b>\n",
        "!pip install langchain faiss-cpu sentence-transformers transformers accelerate pypdf langchain-experimental langchain-groq langchain-community unstructured[all]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yObw6VkH4qaX"
      },
      "source": [
        "# RAG with API's"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB26SnEAEcgP"
      },
      "source": [
        "### Groq API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "J3O3n6ceER9o"
      },
      "outputs": [],
      "source": [
        "#@title <b>RAG implementaion with Groq API </b>\n",
        "import dotenv\n",
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata\n",
        "groq_api_key = userdata.get('GROQ_API_KEY') # @param [\"userdata.get('GROQ_API_KEY')\"] {\"type\":\"raw\",\"allow-input\":true}\n",
        "\n",
        "# ## load the Groq API key\n",
        "# dotenv.load_dotenv()\n",
        "# groq_api_key=os.environ['GROQ_API_KEY']\n",
        "\n",
        "model_name = \"llama-3.2-3b-preview\" # @param [\"llama-3.2-3b-preview\",\"deepseek-r1-distill-llama-70b\",\"llama-3.3-70b-versatile\",\"llama-3.3-70b-specdec\",\"llama-3.2-1b-preview\",\"llama-3.1-8b-instant\",\"llama3-70b-8192\",\"mixtral-8x7b-32768\",\"llama3-8b-8192\",\"llama-guard-3-8b\"]\n",
        "\n",
        "llm=ChatGroq(groq_api_key=groq_api_key,\n",
        "             model_name=model_name,\n",
        "temperature = 0.7 # @param {\"type\":\"number\",\"placeholder\":\"0.7\"}\n",
        "             )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEOheMm8Em7v"
      },
      "source": [
        "### Mistralai API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oOYv6wOofNTw"
      },
      "outputs": [],
      "source": [
        "#@title <b>RAG implementaion with Mistral API\n",
        "from google.colab import userdata\n",
        "\n",
        "mistral_api_key = userdata.get('MISTRAL_API_KEY') # @param [\"userdata.get('MISTRAL_API_KEY')\"] {\"type\":\"raw\",\"allow-input\":true}\n",
        "\n",
        "from langchain_mistralai.chat_models import ChatMistralAI\n",
        "\n",
        "model_name = \"mistral-small-latest\" # @param [\"mistral-small-latest\",\"pixtral-large-latest\",\"codestral-latest\",\"mistral-large-latest\",\"ministral-8b-latest\",\"ministral-3b-latest\",\"open-mistral-nemo\"]\n",
        "\n",
        "llm = ChatMistralAI(\n",
        "    mistral_api_key=mistral_api_key,\n",
        "    model=model_name,\n",
        "    temperature = 0.7 # @param {\"type\":\"number\",\"placeholder\":\"0.7\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE8EvQvaOOT5"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-mistralai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ObpLsQnE5C0"
      },
      "source": [
        "### Google GenerativeAI API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ngc4-nXhjZhX"
      },
      "outputs": [],
      "source": [
        "#@title <b>RAG implementaion with Google GenerativeAI API\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# 1. Configure Google AI Studio get from https://makersuite.google.com/\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY') # @param [\"userdata.get('GOOGLE_API_KEY')\"] {\"type\":\"raw\",\"allow-input\":true}\n",
        "\n",
        "model_name = \"gemini-2.0-flash\" # @param [\"gemini-2.0-flash\",\"gemini-2.0-flash-lite-preview-02-05\",\"gemini-2.0-pro-exp-02-05\",\"gemini-2.0-flash-thinking-exp-01-21\",\"gemini-2.0-flash-exp\",\"learnlm-1.5-pro-experimental\",\"gemini-1.5-pro\",\"gemini-1.5-flash\",\"gemini-1.5-8b\",\"gemini-1.5-flash-8b\"]\n",
        "\n",
        "# 2. Initialize Gemini model\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    google_api_key=GOOGLE_API_KEY,\n",
        "    temperature = 0.7 # @param {\"type\":\"number\",\"placeholder\":\"0.7\"}\n",
        "    ,\n",
        "    convert_system_message_to_human=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l44-V9pdOWN3"
      },
      "outputs": [],
      "source": [
        "!pip install google-generativeai langchain-google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Running RAG with Locally with Ollama**\n"
      ],
      "metadata": {
        "id": "KAOyLHy70w2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Downloading Ollama**\n",
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "id": "_cPg1-hi1FNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash --bg\n",
        "#@title Starting ollama server in colab background\n",
        "ollama serve > /dev/null 2>&1  # Start server in background, suppress logs"
      ],
      "metadata": {
        "id": "pTeac1ZA1lK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl http://localhost:11434  # Should return \"Ollama is running\""
      ],
      "metadata": {
        "id": "wDrKy5G93XCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Downloading Deepseek-r1:7.5b Locally\n",
        "!ollama pull deepseek-r1"
      ],
      "metadata": {
        "id": "6W2T70252sA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#List the local Ollama models\n",
        "!ollama list"
      ],
      "metadata": {
        "id": "JVL7z5723AkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **kill Running Ollama**\n",
        "!pkill -f \"ollama serve\" #Dont run this cell unless u want to stop ollama server"
      ],
      "metadata": {
        "id": "N0ZyBvED4EyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Testing the Deepseek-r1  model in locally\n",
        "!ollama run --verbose deepseek-r1 'hi'"
      ],
      "metadata": {
        "id": "ENjMeIto3nih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U langchain-ollama"
      ],
      "metadata": {
        "id": "CyXg_YJF6eC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Initialize the Ollama model with Python Langchain**\n",
        "\n",
        "from langchain_community.llms import Ollama\n",
        "# from langchain_ollama.llms import OllamaLLM\n",
        "\n",
        "# Initialize the Ollama model\n",
        "llm = Ollama(\n",
        "    model=\"deepseek-r1\",\n",
        "    temperature=0.9,\n",
        "    base_url='http://localhost:11434'\n",
        ")\n",
        "\n",
        "# Run inference\n",
        "response = llm.invoke(\"Explain quantum computing in 3 sentences.\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "RkARqFwP5-Wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZazokNW9FNI-"
      },
      "source": [
        "### Testing LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX3SQP78En4T",
        "outputId": "f0379f83-88c2-4b09-a03a-c47830f05ead"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AIMessage(content=\"Medicaid managed care is a system where a state contracts with managed care organizations (MCOs) to administer healthcare services to Medicaid beneficiaries. Instead of the state directly paying providers for each service (fee-for-service), the state pays the MCO a fixed per-member, per-month (capitation) rate to cover the cost of healthcare for the enrollees in that plan.\\n\\nHere's a breakdown of key aspects:\\n\\n*   **How it works:** States contract with MCOs (which can be HMOs, provider-sponsored organizations, or other types of health plans) to provide a defined set of healthcare services to Medicaid enrollees. Enrollees typically choose a managed care plan from a selection offered in their area.\\n\\n*   **Capitation:** The MCO receives a fixed payment per member per month, regardless of how much or how little healthcare the enrollee uses. This incentivizes the MCO to manage costs and promote preventive care.\\n\\n*   **Network of Providers:** MCOs create and manage a network of doctors, hospitals, and other healthcare providers that enrollees can access. Enrollees typically need to use providers within the plan's network to have their care covered.\\n\\n*   **Goals:** States use managed care to:\\n    *   Control Medicaid costs\\n    *   Improve access to care\\n    *   Enhance the quality of care\\n    *   Promote care coordination\\n\\n*   **Types of Managed Care:** There are different models, including:\\n    *   **Comprehensive Risk-Based Managed Care:** MCOs assume full financial risk for a comprehensive set of services.\\n    *   **Primary Care Case Management (PCCM):** States contract with primary care providers to manage the care of Medicaid enrollees.\\n    *   **Limited Benefit Plans:** MCOs provide a limited set of services, such as behavioral health or dental care.\\n\\n*   **Enrollment:** In many states, Medicaid beneficiaries are required to enroll in a managed care plan. Some populations, such as individuals with disabilities or those requiring long-term care, may be excluded or have specialized managed care options.\\n\\n*   **Oversight:** States and the federal government (Centers for Medicare & Medicaid Services - CMS) oversee Medicaid managed care plans to ensure they meet quality standards, provide adequate access to care, and comply with regulations.\\n\\nIn summary, Medicaid managed care is a significant way that states deliver healthcare services to Medicaid beneficiaries, aiming to improve efficiency, access, and quality of care through contracts with managed care organizations.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-82bbeee1-b1f2-4b46-9b2e-e96fee2acc02-0', usage_metadata={'input_tokens': 24, 'output_tokens': 526, 'total_tokens': 550, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.schema.messages import HumanMessage, SystemMessage\n",
        "messages = [\n",
        " SystemMessage(\n",
        "      content=\"\"\"You're an assistant knowledgeable about\n",
        "     healthcare. Only answer healthcare-related questions.\"\"\"\n",
        "),\n",
        " HumanMessage(content=\"What is Medicaid managed care?\"),\n",
        "]\n",
        "llm.invoke(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q5cCtLqFvUw"
      },
      "source": [
        "# Building a RAG Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LGZFw9plFUqj"
      },
      "outputs": [],
      "source": [
        "#@title <b>Load documents with multiple file support</b>\n",
        "from langchain.document_loaders import DirectoryLoader, PyPDFLoader, TextLoader, UnstructuredMarkdownLoader\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "import os\n",
        "# 1. Load documents with multiple file support\n",
        "def load_documents(path):\n",
        "    loaders = [\n",
        "        DirectoryLoader(path, glob=\"**/*.pdf\", loader_cls=PyPDFLoader),\n",
        "        DirectoryLoader(path, glob=\"**/*.txt\", loader_cls=TextLoader),\n",
        "        DirectoryLoader(path, glob=\"**/*.md\", loader_cls=UnstructuredMarkdownLoader)\n",
        "    ]\n",
        "    documents = []\n",
        "    for loader in loaders:\n",
        "        documents.extend(loader.load())\n",
        "    return documents\n",
        "\n",
        "knowledge_base_path = \"knowledge_base/\" # @param [\"knowledge_base/\"] {\"allow-input\":true}\n",
        "docs = load_documents(knowledge_base_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vFgmxZOfGrQK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "090fbac0-cc1c-4e01-a43e-a4bebd1cc5f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-b426b17fd705>:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  text_splitter = SemanticChunker(HuggingFaceEmbeddings())\n",
            "<ipython-input-4-b426b17fd705>:2: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
            "  text_splitter = SemanticChunker(HuggingFaceEmbeddings())\n"
          ]
        }
      ],
      "source": [
        "#@title <b>Splitting text into semantic chunks</b>\n",
        "text_splitter = SemanticChunker(HuggingFaceEmbeddings())\n",
        "documents = text_splitter.split_documents(docs)\n",
        "##cell completed with cpu 12min 23sec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-0RKCM73L98U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "955bb460-164e-4ffb-ff39-a2528f81713e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.10.6)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.15.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.16.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.16.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.70.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (4.25.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (75.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.67.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-util-http==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting importlib-metadata<=8.5.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.28.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.30.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.51b0-py3-none-any.whl (7.3 kB)\n",
            "Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.15.1-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
            "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53769 sha256=5ae8e93f4964f981d397bf07c31b8ae504ba38a917064bdf2998e4079a23f072\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, pyproject_hooks, protobuf, overrides, opentelemetry-util-http, mmh3, importlib-metadata, humanfriendly, httptools, chroma-hnswlib, bcrypt, asgiref, watchfiles, starlette, posthog, opentelemetry-proto, opentelemetry-api, coloredlogs, build, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.6.1\n",
            "    Uninstalling importlib_metadata-8.6.1:\n",
            "      Successfully uninstalled importlib_metadata-8.6.1\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.16.0\n",
            "    Uninstalling opentelemetry-api-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.16.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.37b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.37b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.16.0\n",
            "    Uninstalling opentelemetry-sdk-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.16.0\n",
            "Successfully installed asgiref-3.8.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.6.3 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.8 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.5.0 kubernetes-32.0.1 mmh3-5.1.0 monotonic-1.6 onnxruntime-1.20.1 opentelemetry-api-1.30.0 opentelemetry-exporter-otlp-proto-common-1.30.0 opentelemetry-exporter-otlp-proto-grpc-1.30.0 opentelemetry-instrumentation-0.51b0 opentelemetry-instrumentation-asgi-0.51b0 opentelemetry-instrumentation-fastapi-0.51b0 opentelemetry-proto-1.30.0 opentelemetry-sdk-1.30.0 opentelemetry-semantic-conventions-0.51b0 opentelemetry-util-http-0.51b0 overrides-7.7.0 posthog-3.15.1 protobuf-5.29.3 pypika-0.48.9 pyproject_hooks-1.2.0 starlette-0.45.3 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata"
                ]
              },
              "id": "a97a76d95952486faf09f9b0e1db1b32"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "f1ET9oPTI3Du",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28b39386-9114-48e2-f302-65762435f8d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-417be59dcf5f>:2: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
            "  embeddings = HuggingFaceEmbeddings()\n"
          ]
        }
      ],
      "source": [
        "# Generate embeddings\n",
        "embeddings = HuggingFaceEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bJUj5kP9Himg"
      },
      "outputs": [],
      "source": [
        "#@title **creating vector store**\n",
        "\n",
        "# from langchain_community.vectorstores import FAISS\n",
        "# vector_store = FAISS.from_documents(documents, embeddings)\n",
        "\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# creating Chroma vector store\n",
        "vector_store = Chroma.from_documents(\n",
        "    documents=documents,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=\"chroma_db\"  # Optional: persist to disk\n",
        ")\n",
        "\n",
        "# Connect retriever (same interface)\n",
        "default_retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})  # Fetch top 3 chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "l_2H3GeiHvtP"
      },
      "outputs": [],
      "source": [
        "#@title **Craft the prompt template**\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "prompt = \"\"\"\n",
        "**Rules**:\n",
        "1. You are a flipkart customer service agent.\n",
        "2. Answer only based on the context.\n",
        "3. If context doesn't contain answer, list common reasons.\n",
        "3. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "4. Keep answers under 4 sentences.\n",
        "5. you can greet to user.\n",
        "6. Format the answer in Markdown.  Include headings, lists, code blocks, and other Markdown elements as appropriate.\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate.from_template(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZC1JxqbDKH3W"
      },
      "outputs": [],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AunWTWh9YSvI"
      },
      "outputs": [],
      "source": [
        "#@title **LLM Max input token truncation**\n",
        "\n",
        "from langchain.schema import BaseRetriever, Document\n",
        "from pydantic import Field\n",
        "from typing import List\n",
        "\n",
        "class TokenSafeRetriever(BaseRetriever):\n",
        "    vector_store: object = Field(...)  # Proper Pydantic field declaration\n",
        "\n",
        "    class Config:\n",
        "        arbitrary_types_allowed = True  # Allow custom vector store type\n",
        "\n",
        "    def _get_relevant_documents(self, query: str, **kwargs) -> List[Document]:\n",
        "        docs = self.vector_store.similarity_search(query, k=3)\n",
        "        encoder = get_encoding(\"cl100k_base\")\n",
        "\n",
        "        # token truncation logic\n",
        "        max_tokens = 3800 # @param {\"type\":\"number\",\"placeholder\":\"3800\"}\n",
        "        current_tokens = 0\n",
        "        filtered_docs = []\n",
        "\n",
        "        for doc in docs:\n",
        "            doc_tokens = len(encoder.encode(doc.page_content))\n",
        "            if current_tokens + doc_tokens <= max_tokens:\n",
        "                filtered_docs.append(doc)\n",
        "                current_tokens += doc_tokens\n",
        "            else:\n",
        "                remaining = max_tokens - current_tokens\n",
        "                truncated = \" \".join(doc.page_content.split()[:int(remaining*0.7)])\n",
        "                filtered_docs.append(Document(\n",
        "                    page_content=truncated,\n",
        "                    metadata=doc.metadata\n",
        "                ))\n",
        "                break\n",
        "\n",
        "        return filtered_docs\n",
        "\n",
        "# Initialize with proper Pydantic\n",
        "custom_retriever = TokenSafeRetriever(vector_store=vector_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "K4-r9H7yH6LT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ec54a5d-24d8-4ddf-fba7-c0d93b9cbc42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-f752aba4d18d>:4: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  llm_chain = LLMChain(llm=llm, prompt=QA_CHAIN_PROMPT)\n",
            "<ipython-input-9-f752aba4d18d>:14: LangChainDeprecationWarning: This class is deprecated. Use the `create_stuff_documents_chain` constructor instead. See migration guide here: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain/\n",
            "  combine_documents_chain=StuffDocumentsChain(\n",
            "<ipython-input-9-f752aba4d18d>:13: LangChainDeprecationWarning: This class is deprecated. Use the `create_retrieval_chain` constructor instead. See migration guide here: https://python.langchain.com/docs/versions/migrating_chains/retrieval_qa/\n",
            "  qa = RetrievalQA(\n"
          ]
        }
      ],
      "source": [
        "#@title **RAG pipeline**\n",
        "from langchain.chains import LLMChain, StuffDocumentsChain\n",
        "# Chain 1: Generate answers\n",
        "llm_chain = LLMChain(llm=llm, prompt=QA_CHAIN_PROMPT)\n",
        "\n",
        "# Chain 2: Combine document chunks\n",
        "document_prompt = PromptTemplate(\n",
        "    template=\"Context:\\ncontent:{page_content}\\nsource:{source}\",\n",
        "    input_variables=[\"page_content\", \"source\"]\n",
        ")\n",
        "\n",
        "# Final RAG pipeline\n",
        "qa = RetrievalQA(\n",
        "    combine_documents_chain=StuffDocumentsChain(\n",
        "        llm_chain=llm_chain,\n",
        "        document_prompt=document_prompt,\n",
        "         document_variable_name=\"context\"\n",
        "    ),\n",
        "    return_source_documents=True,\n",
        "retriever = default_retriever # @param [\"custom_retriever\",\"default_retriever\"] {\"type\":\"raw\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195,
          "referenced_widgets": [
            "b0026061f04d4235b1370bb9fbbe9575",
            "2bcd164d447e457eb89dfb7c4103c121",
            "f9f3e74b86bd4acf984820d9f5a4ab07",
            "993952f478c3474ba3ab39cc0dee69ad",
            "2f3fdb3a85894b5eac8ff0e6f81ada29",
            "298fb28cbdcf4bdb932c311add378ed2",
            "3fa4d5ef90fb4b56b4e49765330f913e",
            "076aa62c02d34da9acda7935c585d162",
            "82eaa23c1a514cb0a132c1eac90b41a2",
            "381a61bc1a59440eb84f3ef982469619",
            "5cbaaa1bc6054ac99ae5627dee44e586",
            "b808a8333aea4562a64e9939e9d8bc9e",
            "057b71af46dc4fdabd29a6a1be6affeb",
            "62cbd808242a4bbda82af90a05c2b98b",
            "069d9857df764297828083d034103540",
            "a2ee65d8792b4583ab33fca3e1ada2cd",
            "f9918db5f36149ea9714384ee8f4c58b",
            "5566b8fc4edd453393aabbc91d69a39c",
            "b36f5a1e165b4710b8ada196f8909f82",
            "5a1d0702dfa24b32a261fd1588edf4e5",
            "69409b81cbc240b0b9993b9d5e4f3693",
            "06ac04bca8be4396a63f5345b9b0c5a2",
            "849f2c001fa04785b5f296d418223914",
            "01436a97736f4fda88909de3c09660d0",
            "7dc1faaf1b0e4630ac52f98cc78247ef",
            "6214f15c3ad04c319c484d086b585ba0",
            "d6f13aab3bd045adb8be96d1cc99293d",
            "9019aa3784634a929789eaae9a558ab0",
            "9838303e451d4e1588b75639f279c099",
            "14daa8d4838048368c9604ed8c58491e",
            "05d75c3553c845d7bae1eb9e97c161f9",
            "bc2cb30d55434b5b95bee8cec3dcc910",
            "88d1175949544f12815008b876ee2819",
            "029233bba890446483872768a48bca72",
            "356f3587892644c8ab05be4944fc7198",
            "e1318e468ded479999cad49069bd5274",
            "a78942f407154de0b20325af50748bf9",
            "d5f1bc6b40d94369af0663b06ab5d2d6",
            "d23431b6969344a997d29c7f825eaa1b",
            "471431a0678440e4a12aed900ba32339",
            "56b7d69c27f54973bf9540d7b9ffdb13",
            "0619ce6e653145aa9bac4feae0c166c4",
            "8dae0e949248495d942626a46bc4db33",
            "3b44749d469f46ada6a14a180ec60d06",
            "7da883b84bc74168b0336f283bdcf188",
            "a45a71f865a349c685788daa2428ea76",
            "e3b4df07f04946b1a133320b6856f5ed",
            "12b32fa15e504ba595b22c0930b28de2",
            "47a4eb6a127d4e4c9aaa5498436ccb28",
            "ad4be8e4189b4c66a0eda72eb43bcf61",
            "47f090c3e7924c67831f4cea9e9defb4",
            "547cc09e68264a2a9f7ff1a77fac7cc0",
            "42636ddcbe7143ad95c98073a0343904",
            "97971e2e738c43dba86f6f2b82ad89e2",
            "0b08eda6bfc849f687d96e2e35a1708c"
          ]
        },
        "id": "Tf_7Ix3SUho3",
        "outputId": "6a57720a-9f27-4316-8c4f-37ab9911ec28"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/953 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0026061f04d4235b1370bb9fbbe9575"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/669M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b808a8333aea4562a64e9939e9d8bc9e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "849f2c001fa04785b5f296d418223914"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "029233bba890446483872768a48bca72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7da883b84bc74168b0336f283bdcf188"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "#@title **Customer Sentiment Analysis**\n",
        "from transformers import pipeline\n",
        "# 1. Sentiment Analysis Model\n",
        "sentiment_analyzer = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        ")\n",
        "\n",
        "# 2. Escalation Check Function\n",
        "def requires_human_escalation(query):\n",
        "    # Check for explicit requests\n",
        "    explicit_triggers = {\n",
        "        \"human agent\", \"talk to manager\", \"supervisor\",\n",
        "        \"real person\", \"angry\", \"frustrated\"\n",
        "    }\n",
        "\n",
        "    if any(trigger in query.lower() for trigger in explicit_triggers):\n",
        "        print('explicit_triggers')\n",
        "        return True\n",
        "\n",
        "    # Analyze sentiment\n",
        "    result = sentiment_analyzer(query)[0]\n",
        "    if result['label'] in ['1 star', '2 stars']:  # Negative sentiment\n",
        "        print(result['score'])\n",
        "        return result['score'] > 0.85  # High confidence\n",
        "\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "zNAYxHFuIKJF",
        "outputId": "b71046d8-0477-4e1a-8393-c9dfb738e43c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your query: Why was my payment declined?\n",
            "0.5234935879707336\n",
            "\n",
            "Bot: I don't have specific information on why your payment was declined. Here are some common reasons:\n",
            "\n",
            "- **Insufficient Funds**: Your account may not have enough balance.\n",
            "- **Incorrect Details**: The payment information provided might be incorrect.\n",
            "- **Card Expiry**: Your card might have expired.\n",
            "- **Security Concerns**: There might be a security issue with your card or account.\n",
            "- **Bank Restrictions**: Your bank might have restrictions on online transactions.\n",
            "\n",
            "Sources: ['knowledge_base/terms.pdf']\n",
            "Enter your query: show me cute cat videos\n",
            "\n",
            "Bot: I'm sorry, but I don't have the capability to show videos. However, you can find cute cat videos on various platforms like YouTube, TikTok, or Instagram. Here are some common reasons why you might not be able to find them directly on Flipkart:\n",
            "\n",
            "1. **Platform Specialization**: Flipkart specializes in e-commerce and does not host video content.\n",
            "2. **Content Availability**: Video content, especially entertainment videos, is typically hosted on platforms designed for media consumption.\n",
            "3. **Search Functionality**: Flipkart's search function is optimized for products and services, not media content.\n",
            "\n",
            "Sources: ['knowledge_base/sitemap.pdf', 'knowledge_base/sitemap.md']\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-9e748cc19fa1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter your query: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'exit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'quit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Retrieve and generate response using \"query\" as the input key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    query = input(\"Enter your query: \")\n",
        "    if query.lower() in ['exit', 'quit',':q']:\n",
        "        break\n",
        "    # Retrieve and generate response using \"query\" as the input key\n",
        "    if requires_human_escalation(query):\n",
        "            print(\"\\nBot: I'm truly sorry you're having this experience. \")\n",
        "            print(\"Let me connect you with a senior support agent immediately.\")\n",
        "            print(\"Please hold while I transfer your chat...\")\n",
        "            # integration with live agent system\n",
        "            break\n",
        "\n",
        "    result = qa({\"query\": query})\n",
        "    full_response = result[\"result\"]\n",
        "\n",
        "    # Extract only the part after \"Answer:\" if present\n",
        "    if \"Answer:\" in full_response:\n",
        "        answer = full_response.split(\"Answer:\")[-1].strip()\n",
        "    else:\n",
        "        answer = full_response.strip()\n",
        "\n",
        "    sources = list(set([doc.metadata[\"source\"] for doc in result[\"source_documents\"]]))\n",
        "\n",
        "    print(f\"\\nBot: {answer}\")\n",
        "    print(f\"\\nSources: {sources}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Integrating RAG Agent into Telegram Bot**"
      ],
      "metadata": {
        "id": "M5-FcfGvpVsl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wlta2j-VtQbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dea4984-478c-42a5-9708-95f2cf11c8f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-telegram-bot\n",
            "  Downloading python_telegram_bot-21.10-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: httpx~=0.27 in /usr/local/lib/python3.11/dist-packages (from python-telegram-bot) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx~=0.27->python-telegram-bot) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx~=0.27->python-telegram-bot) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx~=0.27->python-telegram-bot) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx~=0.27->python-telegram-bot) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx~=0.27->python-telegram-bot) (0.14.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx~=0.27->python-telegram-bot) (1.3.1)\n",
            "Downloading python_telegram_bot-21.10-py3-none-any.whl (669 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m669.5/669.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-telegram-bot\n",
            "Successfully installed python-telegram-bot-21.10\n"
          ]
        }
      ],
      "source": [
        "!pip install python-telegram-bot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nest_asyncio"
      ],
      "metadata": {
        "id": "xZSJ2yhXijmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from telegram import Update\n",
        "from telegram.ext import Application, MessageHandler, filters, ContextTypes\n",
        "import logging\n",
        "from google.colab import userdata\n",
        "import asyncio\n",
        "import nest_asyncio # To run our bot in jupyter notebook\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    level=logging.INFO\n",
        ")\n",
        "\n",
        "async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    query = update.message.text\n",
        "\n",
        "    # Check for exit commands (optional)\n",
        "    if query.lower() in ['exit', 'quit', ':q']:\n",
        "        await update.message.reply_text(\"Goodbye! 👋\")\n",
        "        return\n",
        "\n",
        "    # Human escalation check\n",
        "    if requires_human_escalation(query):\n",
        "        response = (\n",
        "            \"⚠️ I'm truly sorry you're having this experience.\\n\\n\"\n",
        "            \"Let me connect you with a senior support agent immediately...\\n\"\n",
        "            \"Please hold while I transfer your chat ⌛\"\n",
        "        )\n",
        "        await update.message.reply_text(response)\n",
        "        # Add your live agent integration here\n",
        "        return\n",
        "\n",
        "    # Process query with RAG\n",
        "    try:\n",
        "        result = qa({\"query\": query})\n",
        "        full_response = result[\"result\"]\n",
        "\n",
        "        # Extract answer\n",
        "        if \"Answer:\" in full_response:\n",
        "            answer = full_response.split(\"Answer:\")[-1].strip()\n",
        "        else:\n",
        "            answer = full_response.strip()\n",
        "\n",
        "        # Get unique sources\n",
        "        sources = list(set([doc.metadata[\"source\"] for doc in result[\"source_documents\"]]))\n",
        "\n",
        "        # Format response\n",
        "        response = f\"🤖 {answer}\\n\\n📚 Sources:\\n\" + \"\\n\".join(sources)\n",
        "\n",
        "        await update.message.reply_text(response)\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error processing query: {e}\")\n",
        "        await update.message.reply_text(\"⚠️ Sorry, I encountered an error processing your request. Please try again.\")\n",
        "\n",
        "def main():\n",
        "    # Get Telegram token from environment\n",
        "    token =userdata.get('TELEGRAM_BOT_TOKEN') # os.getenv(\"TELEGRAM_BOT_TOKEN\")\n",
        "\n",
        "    # Create Application\n",
        "    application = Application.builder().token(token).build()\n",
        "\n",
        "    # Add message handler\n",
        "    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))\n",
        "\n",
        "    # Start polling\n",
        "    logging.info(\"Bot is running...\")\n",
        "    application.run_polling()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    loop = asyncio.new_event_loop()\n",
        "    asyncio.set_event_loop(loop)\n",
        "    try:\n",
        "        loop.run_until_complete(main())\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "    finally:\n",
        "        loop.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5YXHoRUKUHw2",
        "outputId": "f377eff8-1b6c-4296-d7c1-fb4ac5bd4ee3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:telegram.ext.Application:No error handlers are registered, logging exception.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/ext/_updater.py\", line 750, in _network_loop_retry\n",
            "    if not await do_action():\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/ext/_updater.py\", line 744, in do_action\n",
            "    return action_cb_task.result()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/futures.py\", line 203, in result\n",
            "    raise self._exception.with_traceback(self._exception_tb)\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/ext/_updater.py\", line 371, in polling_action_cb\n",
            "    updates = await self.bot.get_updates(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/ext/_extbot.py\", line 650, in get_updates\n",
            "    updates = await super().get_updates(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/_bot.py\", line 4480, in get_updates\n",
            "    await self._post(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/_bot.py\", line 619, in _post\n",
            "    return await self._do_post(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/ext/_extbot.py\", line 354, in _do_post\n",
            "    return await super()._do_post(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/_bot.py\", line 648, in _do_post\n",
            "    result = await request.post(\n",
            "             ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/request/_baserequest.py\", line 202, in post\n",
            "    result = await self._request_wrapper(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/request/_baserequest.py\", line 385, in _request_wrapper\n",
            "    raise Conflict(message)\n",
            "telegram.error.Conflict: Conflict: terminated by other getUpdates request; make sure that only one bot instance is running\n",
            "ERROR:telegram.ext.Application:No error handlers are registered, logging exception.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/ext/_updater.py\", line 750, in _network_loop_retry\n",
            "    if not await do_action():\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/ext/_updater.py\", line 744, in do_action\n",
            "    return action_cb_task.result()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/futures.py\", line 203, in result\n",
            "    raise self._exception.with_traceback(self._exception_tb)\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/ext/_updater.py\", line 371, in polling_action_cb\n",
            "    updates = await self.bot.get_updates(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/ext/_extbot.py\", line 650, in get_updates\n",
            "    updates = await super().get_updates(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/_bot.py\", line 4480, in get_updates\n",
            "    await self._post(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/_bot.py\", line 619, in _post\n",
            "    return await self._do_post(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/ext/_extbot.py\", line 354, in _do_post\n",
            "    return await super()._do_post(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/_bot.py\", line 648, in _do_post\n",
            "    result = await request.post(\n",
            "             ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/request/_baserequest.py\", line 202, in post\n",
            "    result = await self._request_wrapper(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/request/_baserequest.py\", line 385, in _request_wrapper\n",
            "    raise Conflict(message)\n",
            "telegram.error.Conflict: Conflict: terminated by other getUpdates request; make sure that only one bot instance is running\n",
            "ERROR:telegram.ext.Application:No error handlers are registered, logging exception.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/ext/_updater.py\", line 750, in _network_loop_retry\n",
            "    if not await do_action():\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/ext/_updater.py\", line 744, in do_action\n",
            "    return action_cb_task.result()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/futures.py\", line 203, in result\n",
            "    raise self._exception.with_traceback(self._exception_tb)\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/ext/_updater.py\", line 371, in polling_action_cb\n",
            "    updates = await self.bot.get_updates(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/ext/_extbot.py\", line 650, in get_updates\n",
            "    updates = await super().get_updates(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/_bot.py\", line 4480, in get_updates\n",
            "    await self._post(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/_bot.py\", line 619, in _post\n",
            "    return await self._do_post(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/ext/_extbot.py\", line 354, in _do_post\n",
            "    return await super()._do_post(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/_bot.py\", line 648, in _do_post\n",
            "    result = await request.post(\n",
            "             ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/request/_baserequest.py\", line 202, in post\n",
            "    result = await self._request_wrapper(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/telegram/request/_baserequest.py\", line 385, in _request_wrapper\n",
            "    raise Conflict(message)\n",
            "telegram.error.Conflict: Conflict: terminated by other getUpdates request; make sure that only one bot instance is running\n",
            "<ipython-input-12-069213479d58>:38: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = qa({\"query\": query})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.35317304730415344\n",
            "0.2279803454875946\n",
            "0.46529969573020935\n",
            "0.26928162574768066\n",
            "0.6207744479179382\n",
            "0.5669297575950623\n",
            "0.7431061267852783\n",
            "0.8562032580375671\n",
            "0.6424891352653503\n",
            "0.3556438684463501\n",
            "0.41774696111679077\n",
            "0.29871484637260437\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Cannot close a running event loop",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-069213479d58>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-069213479d58>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;31m# Start polling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Bot is running...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mapplication\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_polling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/telegram/ext/_application.py\u001b[0m in \u001b[0;36mrun_polling\u001b[0;34m(self, poll_interval, timeout, bootstrap_retries, read_timeout, write_timeout, connect_timeout, pool_timeout, allowed_updates, drop_pending_updates, close_loop, stop_signals)\u001b[0m\n\u001b[1;32m    866\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m         return self.__run(\n\u001b[0m\u001b[1;32m    869\u001b[0m             updater_coroutine=self.updater.start_polling(\n\u001b[1;32m    870\u001b[0m                 \u001b[0mpoll_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoll_interval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/telegram/ext/_application.py\u001b[0m in \u001b[0;36m__run\u001b[0;34m(self, updater_coroutine, stop_signals, close_loop)\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mclose_loop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                     \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m     def create_task(\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/unix_events.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finalizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_signal_handlers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/selector_events.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot close a running event loop\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Cannot close a running event loop"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this code only for non-notebook python scripts\n",
        "import logging\n",
        "from telegram import Update\n",
        "from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Enable logging for debugging\n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# /start command handler\n",
        "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
        "    await update.message.reply_text(\"Hello! I'm your simple Telegram bot. How can I help you today?\")\n",
        "\n",
        "# Echo any text message back to the user\n",
        "async def echo(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
        "    # For now, simply echo the incoming message text.\n",
        "    received_text = update.message.text\n",
        "    await update.message.reply_text(received_text)\n",
        "\n",
        "def main() -> None:\n",
        "    # Get Telegram token from environment\n",
        "    token =os.getenv(\"TELEGRAM_BOT_TOKEN\") # userdata.get('TELEGRAM_BOT_TOKEN')\n",
        "    application = Application.builder().token(token).build()\n",
        "\n",
        "    # Add command handler for /start command.\n",
        "    application.add_handler(CommandHandler(\"start\", start))\n",
        "    # Add message handler for text messages.\n",
        "    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, echo))\n",
        "\n",
        "    # Run the bot until the user presses Ctrl-C\n",
        "    application.run_polling()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "YJIKUPE0UUHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VfD3ywKPg0Jg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "KAOyLHy70w2w",
        "ZazokNW9FNI-"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b0026061f04d4235b1370bb9fbbe9575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2bcd164d447e457eb89dfb7c4103c121",
              "IPY_MODEL_f9f3e74b86bd4acf984820d9f5a4ab07",
              "IPY_MODEL_993952f478c3474ba3ab39cc0dee69ad"
            ],
            "layout": "IPY_MODEL_2f3fdb3a85894b5eac8ff0e6f81ada29"
          }
        },
        "2bcd164d447e457eb89dfb7c4103c121": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_298fb28cbdcf4bdb932c311add378ed2",
            "placeholder": "​",
            "style": "IPY_MODEL_3fa4d5ef90fb4b56b4e49765330f913e",
            "value": "config.json: 100%"
          }
        },
        "f9f3e74b86bd4acf984820d9f5a4ab07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_076aa62c02d34da9acda7935c585d162",
            "max": 953,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82eaa23c1a514cb0a132c1eac90b41a2",
            "value": 953
          }
        },
        "993952f478c3474ba3ab39cc0dee69ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_381a61bc1a59440eb84f3ef982469619",
            "placeholder": "​",
            "style": "IPY_MODEL_5cbaaa1bc6054ac99ae5627dee44e586",
            "value": " 953/953 [00:00&lt;00:00, 60.6kB/s]"
          }
        },
        "2f3fdb3a85894b5eac8ff0e6f81ada29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "298fb28cbdcf4bdb932c311add378ed2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fa4d5ef90fb4b56b4e49765330f913e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "076aa62c02d34da9acda7935c585d162": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82eaa23c1a514cb0a132c1eac90b41a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "381a61bc1a59440eb84f3ef982469619": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cbaaa1bc6054ac99ae5627dee44e586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b808a8333aea4562a64e9939e9d8bc9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_057b71af46dc4fdabd29a6a1be6affeb",
              "IPY_MODEL_62cbd808242a4bbda82af90a05c2b98b",
              "IPY_MODEL_069d9857df764297828083d034103540"
            ],
            "layout": "IPY_MODEL_a2ee65d8792b4583ab33fca3e1ada2cd"
          }
        },
        "057b71af46dc4fdabd29a6a1be6affeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9918db5f36149ea9714384ee8f4c58b",
            "placeholder": "​",
            "style": "IPY_MODEL_5566b8fc4edd453393aabbc91d69a39c",
            "value": "model.safetensors: 100%"
          }
        },
        "62cbd808242a4bbda82af90a05c2b98b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b36f5a1e165b4710b8ada196f8909f82",
            "max": 669464588,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a1d0702dfa24b32a261fd1588edf4e5",
            "value": 669464588
          }
        },
        "069d9857df764297828083d034103540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69409b81cbc240b0b9993b9d5e4f3693",
            "placeholder": "​",
            "style": "IPY_MODEL_06ac04bca8be4396a63f5345b9b0c5a2",
            "value": " 669M/669M [00:04&lt;00:00, 152MB/s]"
          }
        },
        "a2ee65d8792b4583ab33fca3e1ada2cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9918db5f36149ea9714384ee8f4c58b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5566b8fc4edd453393aabbc91d69a39c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b36f5a1e165b4710b8ada196f8909f82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a1d0702dfa24b32a261fd1588edf4e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69409b81cbc240b0b9993b9d5e4f3693": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06ac04bca8be4396a63f5345b9b0c5a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "849f2c001fa04785b5f296d418223914": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01436a97736f4fda88909de3c09660d0",
              "IPY_MODEL_7dc1faaf1b0e4630ac52f98cc78247ef",
              "IPY_MODEL_6214f15c3ad04c319c484d086b585ba0"
            ],
            "layout": "IPY_MODEL_d6f13aab3bd045adb8be96d1cc99293d"
          }
        },
        "01436a97736f4fda88909de3c09660d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9019aa3784634a929789eaae9a558ab0",
            "placeholder": "​",
            "style": "IPY_MODEL_9838303e451d4e1588b75639f279c099",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "7dc1faaf1b0e4630ac52f98cc78247ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14daa8d4838048368c9604ed8c58491e",
            "max": 39,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05d75c3553c845d7bae1eb9e97c161f9",
            "value": 39
          }
        },
        "6214f15c3ad04c319c484d086b585ba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc2cb30d55434b5b95bee8cec3dcc910",
            "placeholder": "​",
            "style": "IPY_MODEL_88d1175949544f12815008b876ee2819",
            "value": " 39.0/39.0 [00:00&lt;00:00, 3.34kB/s]"
          }
        },
        "d6f13aab3bd045adb8be96d1cc99293d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9019aa3784634a929789eaae9a558ab0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9838303e451d4e1588b75639f279c099": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14daa8d4838048368c9604ed8c58491e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05d75c3553c845d7bae1eb9e97c161f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc2cb30d55434b5b95bee8cec3dcc910": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88d1175949544f12815008b876ee2819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "029233bba890446483872768a48bca72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_356f3587892644c8ab05be4944fc7198",
              "IPY_MODEL_e1318e468ded479999cad49069bd5274",
              "IPY_MODEL_a78942f407154de0b20325af50748bf9"
            ],
            "layout": "IPY_MODEL_d5f1bc6b40d94369af0663b06ab5d2d6"
          }
        },
        "356f3587892644c8ab05be4944fc7198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d23431b6969344a997d29c7f825eaa1b",
            "placeholder": "​",
            "style": "IPY_MODEL_471431a0678440e4a12aed900ba32339",
            "value": "vocab.txt: 100%"
          }
        },
        "e1318e468ded479999cad49069bd5274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56b7d69c27f54973bf9540d7b9ffdb13",
            "max": 871891,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0619ce6e653145aa9bac4feae0c166c4",
            "value": 871891
          }
        },
        "a78942f407154de0b20325af50748bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dae0e949248495d942626a46bc4db33",
            "placeholder": "​",
            "style": "IPY_MODEL_3b44749d469f46ada6a14a180ec60d06",
            "value": " 872k/872k [00:00&lt;00:00, 23.6MB/s]"
          }
        },
        "d5f1bc6b40d94369af0663b06ab5d2d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d23431b6969344a997d29c7f825eaa1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "471431a0678440e4a12aed900ba32339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56b7d69c27f54973bf9540d7b9ffdb13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0619ce6e653145aa9bac4feae0c166c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8dae0e949248495d942626a46bc4db33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b44749d469f46ada6a14a180ec60d06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7da883b84bc74168b0336f283bdcf188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a45a71f865a349c685788daa2428ea76",
              "IPY_MODEL_e3b4df07f04946b1a133320b6856f5ed",
              "IPY_MODEL_12b32fa15e504ba595b22c0930b28de2"
            ],
            "layout": "IPY_MODEL_47a4eb6a127d4e4c9aaa5498436ccb28"
          }
        },
        "a45a71f865a349c685788daa2428ea76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad4be8e4189b4c66a0eda72eb43bcf61",
            "placeholder": "​",
            "style": "IPY_MODEL_47f090c3e7924c67831f4cea9e9defb4",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "e3b4df07f04946b1a133320b6856f5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_547cc09e68264a2a9f7ff1a77fac7cc0",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_42636ddcbe7143ad95c98073a0343904",
            "value": 112
          }
        },
        "12b32fa15e504ba595b22c0930b28de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97971e2e738c43dba86f6f2b82ad89e2",
            "placeholder": "​",
            "style": "IPY_MODEL_0b08eda6bfc849f687d96e2e35a1708c",
            "value": " 112/112 [00:00&lt;00:00, 6.39kB/s]"
          }
        },
        "47a4eb6a127d4e4c9aaa5498436ccb28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad4be8e4189b4c66a0eda72eb43bcf61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47f090c3e7924c67831f4cea9e9defb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "547cc09e68264a2a9f7ff1a77fac7cc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42636ddcbe7143ad95c98073a0343904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97971e2e738c43dba86f6f2b82ad89e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b08eda6bfc849f687d96e2e35a1708c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}